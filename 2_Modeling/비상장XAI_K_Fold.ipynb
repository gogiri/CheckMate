{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import recall_score,precision_score, f1_score, roc_auc_score, confusion_matrix ,make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False  # MINUS SIGN 사용 비활성화\n",
    "mpl.rcParams['font.family'] = 'NanumGothic'  # 또는 다른 폰트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../파생변수데이터셋/외감_파생_ir.csv')\n",
    "columns = ['이윤분배율', 'log총자산', '매출액순이익률', '비유동자산증가율', '부채비율', \n",
    "        '차입금의존도', '총자본순이익률', '자기자본구성비율', '비유동자산회전률', '매출액증가율', '부가가치율']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18546"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['y']==1]['거래소코드'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능확인 코드\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    roc_score = roc_auc_score(y_test, pred)\n",
    "    pr_score = average_precision_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    f2 = fbeta_score(y_test, pred, beta=2)\n",
    "    # G-mean 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도 : {1:.4f}, 재현율:{2:.4f},F1 스코어:{3:.4f}, f2 :{4:.4f}'.format(accuracy, precision, recall, f1, f2))\n",
    "    print('ROC 스코어: {0:.4f}, PR 스코어 : {1:.4f}, G-mean : {2:.4f}'.format(roc_score, pr_score, gmean))\n",
    "\n",
    "# 임계값에 따른 오차행렬및 스코어 -------->#임계값 최적 : 재현율기준(0.1)/f1기준(0.3)\n",
    "from sklearn.preprocessing import Binarizer\n",
    "thresholds = [0.1,0.15,0.2,0.25,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        # ROC 커브 계산\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(\"임곗값:\", custom_threshold)\n",
    "        print(\"ROC_AUC:\", roc_auc)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        print(\"---------------------------------------------------------\")\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def roc(model,name) :\n",
    "    # 테스트 데이터에 대한 예측 확률 계산\n",
    "    pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC 커브 계산\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred)\n",
    "\n",
    "    # AUC 계산\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # ROC 커브에 AUC 면적에 색을 입히는 코드 수정\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # ROC 커브 시각화 및 AUC 면적 색칠\n",
    "    plt.fill_between(fpr, tpr, color='palegoldenrod', alpha=0.4, label=f'Area under curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot(fpr, tpr, color='peru', lw=2)\n",
    "\n",
    "    # 기본 설정\n",
    "    plt.plot([0, 1], [0, 1], color='darkorange', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 레이블 y가 1인 경우에 대한 처리\n",
    "for i in columns:\n",
    "    # 무한대 값 제외하고 최대값, 최소값 계산\n",
    "    max_value = df.loc[(df['y'] == 1) & (np.isfinite(df[i])), i].max()\n",
    "    min_value = df.loc[(df['y'] == 1) & (np.isfinite(df[i])), i].min()\n",
    "\n",
    "    # 무한대 값을 최대값 또는 최소값으로 대체\n",
    "    df.loc[(df['y'] == 1) & (df[i] == np.inf), i] = max_value\n",
    "    df.loc[(df['y'] == 1) & (df[i] == -np.inf), i] = min_value\n",
    "\n",
    "# 클래스 레이블 y가 0인 경우에 대한 처리\n",
    "for i in columns:\n",
    "    # 무한대 값 제외하고 최대값, 최소값 계산\n",
    "    max_value = df.loc[(df['y'] == 0) & (np.isfinite(df[i])), i].max()\n",
    "    min_value = df.loc[(df['y'] == 0) & (np.isfinite(df[i])), i].min()\n",
    "\n",
    "    # 무한대 값을 최대값 또는 최소값으로 대체\n",
    "    df.loc[(df['y'] == 0) & (df[i] == np.inf), i] = max_value\n",
    "    df.loc[(df['y'] == 0) & (df[i] == -np.inf), i] = min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['회계년도'] <= '2020-11-01']\n",
    "test = df[df['회계년도'] >= '2020-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101635"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88231, 13404)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['y']==0]['y']), len(train[train['y']==1]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45874, 6199)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[test['y']==0]['y']), len(test[test['y']==1]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이윤분배율</th>\n",
       "      <th>log총자산</th>\n",
       "      <th>매출액순이익률</th>\n",
       "      <th>비유동자산증가율</th>\n",
       "      <th>부채비율</th>\n",
       "      <th>차입금의존도</th>\n",
       "      <th>총자본순이익률</th>\n",
       "      <th>자기자본구성비율</th>\n",
       "      <th>비유동자산회전률</th>\n",
       "      <th>매출액증가율</th>\n",
       "      <th>부가가치율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "      <td>101635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.635099</td>\n",
       "      <td>7.471867</td>\n",
       "      <td>-11.060317</td>\n",
       "      <td>16.895618</td>\n",
       "      <td>366.768568</td>\n",
       "      <td>34.693735</td>\n",
       "      <td>2.398172</td>\n",
       "      <td>44.087379</td>\n",
       "      <td>8.076822</td>\n",
       "      <td>19.910724</td>\n",
       "      <td>16.078776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.336406</td>\n",
       "      <td>0.429932</td>\n",
       "      <td>179.727287</td>\n",
       "      <td>103.003094</td>\n",
       "      <td>1634.431960</td>\n",
       "      <td>30.970550</td>\n",
       "      <td>12.026207</td>\n",
       "      <td>26.898089</td>\n",
       "      <td>33.987769</td>\n",
       "      <td>150.577782</td>\n",
       "      <td>91.225844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1838.270000</td>\n",
       "      <td>5.993832</td>\n",
       "      <td>-4036.770000</td>\n",
       "      <td>-96.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-118.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-91.440000</td>\n",
       "      <td>-1932.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.570000</td>\n",
       "      <td>7.178010</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-4.770000</td>\n",
       "      <td>41.305000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>23.440000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>-9.140000</td>\n",
       "      <td>7.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.370000</td>\n",
       "      <td>7.382056</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>119.820000</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>41.400000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>15.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.200000</td>\n",
       "      <td>7.683425</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>269.585000</td>\n",
       "      <td>54.050000</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>64.965000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>27.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.250000</td>\n",
       "      <td>8.997554</td>\n",
       "      <td>119.590000</td>\n",
       "      <td>2122.420000</td>\n",
       "      <td>33825.010000</td>\n",
       "      <td>292.300000</td>\n",
       "      <td>36.380000</td>\n",
       "      <td>98.210000</td>\n",
       "      <td>650.920000</td>\n",
       "      <td>3127.300000</td>\n",
       "      <td>175.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               이윤분배율         log총자산        매출액순이익률       비유동자산증가율  \\\n",
       "count  101635.000000  101635.000000  101635.000000  101635.000000   \n",
       "mean        2.635099       7.471867     -11.060317      16.895618   \n",
       "std       115.336406       0.429932     179.727287     103.003094   \n",
       "min     -1838.270000       5.993832   -4036.770000     -96.800000   \n",
       "25%         0.570000       7.178010       0.050000      -4.770000   \n",
       "50%        18.370000       7.382056       2.470000       0.320000   \n",
       "75%        39.200000       7.683425       7.370000      12.820000   \n",
       "max        93.250000       8.997554     119.590000    2122.420000   \n",
       "\n",
       "                부채비율         차입금의존도        총자본순이익률       자기자본구성비율  \\\n",
       "count  101635.000000  101635.000000  101635.000000  101635.000000   \n",
       "mean      366.768568      34.693735       2.398172      44.087379   \n",
       "std      1634.431960      30.970550      12.026207      26.898089   \n",
       "min         0.000000       0.000000    -118.180000       0.000000   \n",
       "25%        41.305000       7.040000       0.070000      23.440000   \n",
       "50%       119.820000      31.830000       2.450000      41.400000   \n",
       "75%       269.585000      54.050000       6.720000      64.965000   \n",
       "max     33825.010000     292.300000      36.380000      98.210000   \n",
       "\n",
       "            비유동자산회전률         매출액증가율          부가가치율  \n",
       "count  101635.000000  101635.000000  101635.000000  \n",
       "mean        8.076822      19.910724      16.078776  \n",
       "std        33.987769     150.577782      91.225844  \n",
       "min         0.000000     -91.440000   -1932.130000  \n",
       "25%         0.670000      -9.140000       7.740000  \n",
       "50%         1.780000       1.170000      15.270000  \n",
       "75%         4.290000      15.050000      27.810000  \n",
       "max       650.920000    3127.300000     175.200000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "\n",
    "# 데이터프레임의 각 열에 대해 winsorize를 적용\n",
    "for col in columns:\n",
    "    # y == 1인 경우\n",
    "    train.loc[train['y'] == 1, col] = winsorize(train.loc[train['y'] == 1, col], limits=[0.01, 0.01])\n",
    "    test.loc[test['y'] == 1, col] = winsorize(test.loc[test['y'] == 1, col], limits=[0.01, 0.01])\n",
    "\n",
    "    # y == 0인 경우\n",
    "    train.loc[train['y'] == 0, col] = winsorize(train.loc[train['y'] == 0, col], limits=[0.01, 0.01])\n",
    "    test.loc[test['y'] == 0, col] = winsorize(test.loc[test['y'] == 0, col], limits=[0.01, 0.01])\n",
    "\n",
    "# 결과 확인\n",
    "train[columns].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# 스케일러 초기화\n",
    "scaler = StandardScaler()\n",
    "scale_columns = columns\n",
    "\n",
    "# 훈련 데이터에 대해 스케일러 학습 및 변환\n",
    "train.loc[:,scale_columns] = scaler.fit_transform(train[scale_columns])\n",
    "\n",
    "# 테스트 데이터 변환 (훈련 데이터로부터 학습된 파라미터 사용)\n",
    "test.loc[:,scale_columns] = scaler.transform(test[scale_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_y 분류\n",
    "y_train = train['y']\n",
    "X_train = train[columns]\n",
    "\n",
    "y_test = test['y']\n",
    "X_test = test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101635, 59), (112764, 11))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours\n",
    "\n",
    "# smote = BorderlineSMOTE(k_neighbors=7, m_neighbors=7,sampling_strategy=0.25, random_state=17)\n",
    "smote = ADASYN(n_neighbors=5,sampling_strategy=0.3, random_state=17)\n",
    "# under = EditedNearestNeighbours(n_neighbors=5)\n",
    "# SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "# X_test, y_test = under.fit_resample(X_test,y_test)\n",
    "# Checking the shape of the original and resampled data\n",
    "original_shape = train.shape\n",
    "resampled_shape = X_resampled.shape\n",
    "\n",
    "original_shape, resampled_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.countplot(x=\"y\", data=df[['y']])\n",
    "plt.title(\"정상 / 부도 데이터수 (비상장)\")\n",
    "\n",
    "# 각 막대 위에 숫자 표시\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 두 데이터셋을 시각화합니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "# 첫 번째 데이터셋\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=\"y\", data=train[['y']], ax=ax1)\n",
    "plt.title(\"정상 / 부도 데이터수 (비상장) Before\")\n",
    "\n",
    "# 각 막대 위에 숫자 표시\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "    \n",
    "# 두 번째 데이터셋 (시리즈)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "sns.countplot(x=y_resampled, ax=ax2)\n",
    "plt.title(\"정상 / 부도 데이터수 (비상장) After\")\n",
    "\n",
    "# 각 막대 위에 숫자 표시\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이윤분배율</th>\n",
       "      <th>log총자산</th>\n",
       "      <th>매출액순이익률</th>\n",
       "      <th>비유동자산증가율</th>\n",
       "      <th>부채비율</th>\n",
       "      <th>차입금의존도</th>\n",
       "      <th>총자본순이익률</th>\n",
       "      <th>자기자본구성비율</th>\n",
       "      <th>비유동자산회전률</th>\n",
       "      <th>매출액증가율</th>\n",
       "      <th>부가가치율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.270383</td>\n",
       "      <td>3.548689</td>\n",
       "      <td>0.068383</td>\n",
       "      <td>-0.124420</td>\n",
       "      <td>-0.144319</td>\n",
       "      <td>-0.731787</td>\n",
       "      <td>-0.087989</td>\n",
       "      <td>-0.028901</td>\n",
       "      <td>-0.108770</td>\n",
       "      <td>-0.039121</td>\n",
       "      <td>-0.136352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029522</td>\n",
       "      <td>3.548689</td>\n",
       "      <td>0.062541</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>-0.150419</td>\n",
       "      <td>-0.704664</td>\n",
       "      <td>-0.182783</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.129071</td>\n",
       "      <td>-0.174733</td>\n",
       "      <td>-0.144025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.092902</td>\n",
       "      <td>3.548689</td>\n",
       "      <td>0.064099</td>\n",
       "      <td>-0.174128</td>\n",
       "      <td>-0.162858</td>\n",
       "      <td>-0.836726</td>\n",
       "      <td>-0.161995</td>\n",
       "      <td>0.214240</td>\n",
       "      <td>-0.149961</td>\n",
       "      <td>-0.218630</td>\n",
       "      <td>-0.138106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.022847</td>\n",
       "      <td>3.548689</td>\n",
       "      <td>-0.015689</td>\n",
       "      <td>-0.242961</td>\n",
       "      <td>-0.135674</td>\n",
       "      <td>-0.688520</td>\n",
       "      <td>-1.158157</td>\n",
       "      <td>-0.121845</td>\n",
       "      <td>-0.160259</td>\n",
       "      <td>-0.237956</td>\n",
       "      <td>-0.318429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177611</td>\n",
       "      <td>3.548689</td>\n",
       "      <td>0.066992</td>\n",
       "      <td>0.191688</td>\n",
       "      <td>-0.132394</td>\n",
       "      <td>-0.469278</td>\n",
       "      <td>-0.120419</td>\n",
       "      <td>-0.154189</td>\n",
       "      <td>-0.159082</td>\n",
       "      <td>-0.033011</td>\n",
       "      <td>-0.129885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141554</th>\n",
       "      <td>0.541071</td>\n",
       "      <td>-1.672526</td>\n",
       "      <td>0.115678</td>\n",
       "      <td>1.979702</td>\n",
       "      <td>-0.122305</td>\n",
       "      <td>-0.038222</td>\n",
       "      <td>2.825662</td>\n",
       "      <td>-0.246018</td>\n",
       "      <td>0.333450</td>\n",
       "      <td>2.636652</td>\n",
       "      <td>-0.012264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142391</th>\n",
       "      <td>-0.022847</td>\n",
       "      <td>-0.466359</td>\n",
       "      <td>0.022536</td>\n",
       "      <td>2.456194</td>\n",
       "      <td>0.611905</td>\n",
       "      <td>1.458692</td>\n",
       "      <td>-1.052554</td>\n",
       "      <td>-1.385510</td>\n",
       "      <td>-0.114066</td>\n",
       "      <td>-0.174666</td>\n",
       "      <td>-0.209906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146707</th>\n",
       "      <td>-0.022847</td>\n",
       "      <td>-1.085619</td>\n",
       "      <td>-0.367056</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>-0.224402</td>\n",
       "      <td>1.933016</td>\n",
       "      <td>-1.996331</td>\n",
       "      <td>-1.639061</td>\n",
       "      <td>-0.225871</td>\n",
       "      <td>-0.593123</td>\n",
       "      <td>-0.889542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146713</th>\n",
       "      <td>-0.265877</td>\n",
       "      <td>-2.287038</td>\n",
       "      <td>-0.047459</td>\n",
       "      <td>-1.103813</td>\n",
       "      <td>-0.224402</td>\n",
       "      <td>1.205547</td>\n",
       "      <td>-1.065027</td>\n",
       "      <td>-1.639061</td>\n",
       "      <td>-0.219987</td>\n",
       "      <td>-0.126319</td>\n",
       "      <td>0.589761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146715</th>\n",
       "      <td>-0.022847</td>\n",
       "      <td>0.547618</td>\n",
       "      <td>-12.347934</td>\n",
       "      <td>-0.487421</td>\n",
       "      <td>-0.224402</td>\n",
       "      <td>3.034713</td>\n",
       "      <td>-2.748858</td>\n",
       "      <td>-1.639061</td>\n",
       "      <td>-0.234698</td>\n",
       "      <td>-0.132229</td>\n",
       "      <td>-14.915022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101635 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           이윤분배율    log총자산    매출액순이익률  비유동자산증가율      부채비율    차입금의존도   총자본순이익률  \\\n",
       "0       0.270383  3.548689   0.068383 -0.124420 -0.144319 -0.731787 -0.087989   \n",
       "1       0.029522  3.548689   0.062541  0.009460 -0.150419 -0.704664 -0.182783   \n",
       "2       0.092902  3.548689   0.064099 -0.174128 -0.162858 -0.836726 -0.161995   \n",
       "3      -0.022847  3.548689  -0.015689 -0.242961 -0.135674 -0.688520 -1.158157   \n",
       "4       0.177611  3.548689   0.066992  0.191688 -0.132394 -0.469278 -0.120419   \n",
       "...          ...       ...        ...       ...       ...       ...       ...   \n",
       "141554  0.541071 -1.672526   0.115678  1.979702 -0.122305 -0.038222  2.825662   \n",
       "142391 -0.022847 -0.466359   0.022536  2.456194  0.611905  1.458692 -1.052554   \n",
       "146707 -0.022847 -1.085619  -0.367056  0.011207 -0.224402  1.933016 -1.996331   \n",
       "146713 -0.265877 -2.287038  -0.047459 -1.103813 -0.224402  1.205547 -1.065027   \n",
       "146715 -0.022847  0.547618 -12.347934 -0.487421 -0.224402  3.034713 -2.748858   \n",
       "\n",
       "        자기자본구성비율  비유동자산회전률    매출액증가율      부가가치율  \n",
       "0      -0.028901 -0.108770 -0.039121  -0.136352  \n",
       "1       0.043595 -0.129071 -0.174733  -0.144025  \n",
       "2       0.214240 -0.149961 -0.218630  -0.138106  \n",
       "3      -0.121845 -0.160259 -0.237956  -0.318429  \n",
       "4      -0.154189 -0.159082 -0.033011  -0.129885  \n",
       "...          ...       ...       ...        ...  \n",
       "141554 -0.246018  0.333450  2.636652  -0.012264  \n",
       "142391 -1.385510 -0.114066 -0.174666  -0.209906  \n",
       "146707 -1.639061 -0.225871 -0.593123  -0.889542  \n",
       "146713 -1.639061 -0.219987 -0.126319   0.589761  \n",
       "146715 -1.639061 -0.234698 -0.132229 -14.915022  \n",
       "\n",
       "[101635 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_Accuracy_Scores: [0.8723008  0.87988294 0.85762426 0.80100208 0.67980667]\n",
      "CV_Precision_Scores: [0.97028784 0.9375     0.83281005 0.59365221 0.28935396]\n",
      "CV_Recall_Scores: [0.42600897 0.47992664 0.43244345 0.27063379 0.32409295]\n",
      "CV_F1_Scores: [0.59206799 0.63485645 0.56928236 0.37178052 0.30573983]\n",
      "CV_ROC/AUC: [0.91166677 0.92860389 0.82756673 0.76579842 0.61156725]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.82\n",
      "CV_Precision_mean: 0.72\n",
      "CV_Recall_mean: 0.39\n",
      "CV_F1_스코어_mean: 0.49\n",
      "CV_ROC_AUC+스코어_mean: 0.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression\n",
       "Accuracy                 0.82\n",
       "Precision                0.72\n",
       "Recall                   0.39\n",
       "F1                       0.49\n",
       "ROC AUC                  0.81"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Kfold\n",
    "SPLITS = 5\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "# 모델 생성\n",
    "cv_logit_model = LogisticRegression(\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.2f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.2f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.2f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.2f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.2f}')\n",
    "\n",
    "# cv 결과 저장\n",
    "cv_result_logit = {\n",
    "    'Accuracy' : round(cv_accuracy.mean(), 2),\n",
    "    'Precision': round(cv_precision.mean(), 2),\n",
    "    'Recall' : round(cv_recall.mean(), 2),\n",
    "    'F1' : round(cv_f1.mean(), 2),\n",
    "    'ROC AUC' : round(cv_roc_auc.mean(), 2)\n",
    "}\n",
    "validation['LogisticRegression'] = cv_result_logit\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_Accuracy_Scores: [0.91779364 0.862546   0.84893362 0.79310956 0.69909542]\n",
      "CV_Precision_Scores: [1.         1.         1.         1.         0.32663224]\n",
      "CV_Recall_Scores: [0.62209539 0.36824944 0.30568576 0.04911351 0.36098655]\n",
      "CV_F1_Scores: [0.76702689 0.53827822 0.46823786 0.09362859 0.3429512 ]\n",
      "CV_ROC/AUC: [0.89628234 0.91464725 0.83667177 0.75446417 0.6453002 ]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.82\n",
      "CV_Precision_mean: 0.87\n",
      "CV_Recall_mean: 0.34\n",
      "CV_F1_스코어_mean: 0.44\n",
      "CV_ROC_AUC+스코어_mean: 0.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression    DT\n",
       "Accuracy                 0.82  0.82\n",
       "Precision                0.72  0.87\n",
       "Recall                   0.39  0.34\n",
       "F1                       0.49  0.44\n",
       "ROC AUC                  0.81  0.81"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Kfold\n",
    "SPLITS = 5\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "# 모델 생성\n",
    "cv_logit_model = DecisionTreeClassifier(random_state=17, \n",
    "                            max_depth=3, \n",
    "                            )\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.2f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.2f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.2f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.2f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.2f}')\n",
    "\n",
    "# cv 결과 저장\n",
    "cv_result_logit = {\n",
    "    'Accuracy' : round(cv_accuracy.mean(), 2),\n",
    "    'Precision': round(cv_precision.mean(), 2),\n",
    "    'Recall' : round(cv_recall.mean(), 2),\n",
    "    'F1' : round(cv_f1.mean(), 2),\n",
    "    'ROC AUC' : round(cv_roc_auc.mean(), 2)\n",
    "}\n",
    "validation['DT'] = cv_result_logit\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_Accuracy_Scores: [0.96514876 0.94750144 0.92413426 0.89766328 0.81664597]\n",
      "CV_Precision_Scores: [0.98334115 0.97019449 0.92590618 0.82366127 0.5662485 ]\n",
      "CV_Recall_Scores: [0.85426009 0.78275932 0.70796821 0.67393519 0.67162658]\n",
      "CV_F1_Scores: [0.91426702 0.86645612 0.80240212 0.74131361 0.61445221]\n",
      "CV_ROC/AUC: [0.991082   0.98829109 0.96158856 0.94554086 0.86751875]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.91\n",
      "CV_Precision_mean: 0.85\n",
      "CV_Recall_mean: 0.74\n",
      "CV_F1_스코어_mean: 0.79\n",
      "CV_ROC_AUC+스코어_mean: 0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression    DT    RF\n",
       "Accuracy                 0.82  0.82  0.91\n",
       "Precision                0.72  0.87  0.85\n",
       "Recall                   0.39  0.34  0.74\n",
       "F1                       0.49  0.44  0.79\n",
       "ROC AUC                  0.81  0.81  0.95"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Kfold\n",
    "SPLITS = 5\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "# 모델 생성\n",
    "cv_logit_model = RandomForestClassifier(random_state=17, \n",
    "                            )\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.2f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.2f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.2f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.2f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.2f}')\n",
    "\n",
    "# cv 결과 저장\n",
    "cv_result_logit = {\n",
    "    'Accuracy' : round(cv_accuracy.mean(), 2),\n",
    "    'Precision': round(cv_precision.mean(), 2),\n",
    "    'Recall' : round(cv_recall.mean(), 2),\n",
    "    'F1' : round(cv_f1.mean(), 2),\n",
    "    'ROC AUC' : round(cv_roc_auc.mean(), 2)\n",
    "}\n",
    "validation['RF'] = cv_result_logit\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217568 -> initscore=-1.279897\n",
      "[LightGBM] [Info] Start training from score -1.279897\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90212, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217565 -> initscore=-1.279911\n",
      "[LightGBM] [Info] Start training from score -1.279911\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217568 -> initscore=-1.279897\n",
      "[LightGBM] [Info] Start training from score -1.279897\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90212, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217565 -> initscore=-1.279911\n",
      "[LightGBM] [Info] Start training from score -1.279911\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217568 -> initscore=-1.279897\n",
      "[LightGBM] [Info] Start training from score -1.279897\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90212, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217565 -> initscore=-1.279911\n",
      "[LightGBM] [Info] Start training from score -1.279911\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217568 -> initscore=-1.279897\n",
      "[LightGBM] [Info] Start training from score -1.279897\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90212, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217565 -> initscore=-1.279911\n",
      "[LightGBM] [Info] Start training from score -1.279911\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217568 -> initscore=-1.279897\n",
      "[LightGBM] [Info] Start training from score -1.279897\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19626, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90211, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217557 -> initscore=-1.279962\n",
      "[LightGBM] [Info] Start training from score -1.279962\n",
      "[LightGBM] [Info] Number of positive: 19627, number of negative: 70585\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 90212, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217565 -> initscore=-1.279911\n",
      "[LightGBM] [Info] Start training from score -1.279911\n",
      "CV_Accuracy_Scores: [0.95104864 0.92045404 0.89455948 0.84365716 0.76578574]\n",
      "CV_Precision_Scores: [0.96593137 0.94458726 0.87622731 0.70314798 0.46353763]\n",
      "CV_Recall_Scores: [0.80330208 0.67393519 0.60016303 0.4870593  0.48715858]\n",
      "CV_F1_Scores: [0.87714222 0.78663178 0.7123851  0.5754876  0.47505466]\n",
      "CV_ROC/AUC: [0.98185931 0.97521772 0.92505101 0.88850228 0.80428542]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.88\n",
      "CV_Precision_mean: 0.79\n",
      "CV_Recall_mean: 0.61\n",
      "CV_F1_스코어_mean: 0.69\n",
      "CV_ROC_AUC+스코어_mean: 0.91\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression    DT    RF  LGBM\n",
       "Accuracy                 0.82  0.82  0.91  0.88\n",
       "Precision                0.72  0.87  0.85  0.79\n",
       "Recall                   0.39  0.34  0.74  0.61\n",
       "F1                       0.49  0.44  0.79  0.69\n",
       "ROC AUC                  0.81  0.81  0.95  0.91"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kfold\n",
    "SPLITS = 5\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "cv_logit_model = LGBMClassifier(random_state=17\n",
    "                    )\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.2f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.2f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.2f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.2f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.2f}')\n",
    "\n",
    "# cv 결과 저장\n",
    "cv_result_logit = {\n",
    "    'Accuracy' : round(cv_accuracy.mean(), 2),\n",
    "    'Precision': round(cv_precision.mean(), 2),\n",
    "    'Recall' : round(cv_recall.mean(), 2),\n",
    "    'F1' : round(cv_f1.mean(), 2),\n",
    "    'ROC AUC' : round(cv_roc_auc.mean(), 2)\n",
    "}\n",
    "validation['LGBM'] = cv_result_logit\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_Accuracy_Scores: [0.93184942 0.88063672 0.86706868 0.8157673  0.75536538]\n",
      "CV_Precision_Scores: [0.9952955  0.9863856  0.96904177 0.77089337 0.41920127]\n",
      "CV_Recall_Scores: [0.68997146 0.45771347 0.40187487 0.21805584 0.32307379]\n",
      "CV_F1_Scores: [0.81497532 0.6252784  0.56813598 0.33995234 0.36491309]\n",
      "CV_ROC/AUC: [0.96887195 0.96152273 0.89237538 0.84541526 0.72281617]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.85\n",
      "CV_Precision_mean: 0.83\n",
      "CV_Recall_mean: 0.42\n",
      "CV_F1_스코어_mean: 0.54\n",
      "CV_ROC_AUC+스코어_mean: 0.88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression    DT    RF  LGBM   XGB\n",
       "Accuracy                 0.82  0.82  0.91  0.88  0.85\n",
       "Precision                0.72  0.87  0.85  0.79  0.83\n",
       "Recall                   0.39  0.34  0.74  0.61  0.42\n",
       "F1                       0.49  0.44  0.79  0.69  0.54\n",
       "ROC AUC                  0.81  0.81  0.95  0.91  0.88"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Kfold\n",
    "SPLITS = 5\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "cv_logit_model = XGBClassifier(random_state=17,\n",
    "                    n_estimators=90,\n",
    "                    max_depth=5,\n",
    "                    learning_rate=0.03,\n",
    "                    reg_lambda=2,\n",
    "                    reg_alpha=0.02,\n",
    "                    min_split_loss=2\n",
    "                    )\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(cv_logit_model, X_resampled, y_resampled, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.2f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.2f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.2f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.2f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.2f}')\n",
    "\n",
    "# cv 결과 저장\n",
    "cv_result_logit = {\n",
    "    'Accuracy' : round(cv_accuracy.mean(), 2),\n",
    "    'Precision': round(cv_precision.mean(), 2),\n",
    "    'Recall' : round(cv_recall.mean(), 2),\n",
    "    'F1' : round(cv_f1.mean(), 2),\n",
    "    'ROC AUC' : round(cv_roc_auc.mean(), 2)\n",
    "}\n",
    "validation['XGB'] = cv_result_logit\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
